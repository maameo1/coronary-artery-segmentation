{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# ImageCAS Training Pipeline\n",
    "\n",
    "This notebook demonstrates the complete training pipeline for coronary artery segmentation using the ImageCAS dataset.\n",
    "\n",
    "**Contents:**\n",
    "1. Dataset exploration and loading\n",
    "2. Data preprocessing and augmentation\n",
    "3. Model setup (U-Net with transfer learning)\n",
    "4. Training loop\n",
    "5. Evaluation and visualization\n",
    "6. Results analysis across different data regimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "# Core libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "\n",
    "# MONAI imports\n",
    "from monai.transforms import (\n",
    "    Compose, LoadImaged, EnsureChannelFirstd, Spacingd,\n",
    "    ScaleIntensityRanged, RandCropByPosNegLabeld, RandFlipd,\n",
    "    RandRotate90d, ToTensord\n",
    ")\n",
    "from monai.data import Dataset, DataLoader, CacheDataset\n",
    "from monai.networks.nets import UNet\n",
    "from monai.losses import DiceLoss, DiceCELoss\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.inferers import sliding_window_inference\n",
    "\n",
    "# Visualization\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "%matplotlib inline\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## 1. Configuration Loading\n",
    "\n",
    "Load the base configuration and any specific data regime settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load base configuration\n",
    "config_path = Path('../configs/base_config.yaml')\n",
    "\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "print(\"Base Configuration:\")\n",
    "print(yaml.dump(config, default_flow_style=False))\n",
    "\n",
    "# Optional: Load a specific data regime\n",
    "# regime_path = Path('../configs/data_regimes/regime_20.yaml')\n",
    "# with open(regime_path, 'r') as f:\n",
    "#     regime_config = yaml.safe_load(f)\n",
    "#     config.update(regime_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## 2. Dataset Exploration\n",
    "\n",
    "Explore the ImageCAS dataset structure and contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data directory\n",
    "data_dir = Path(config['data']['data_dir'])\n",
    "\n",
    "# Check if directory exists\n",
    "if not data_dir.exists():\n",
    "    print(f\"⚠️  Data directory not found: {data_dir}\")\n",
    "    print(\"Please download the ImageCAS dataset from Kaggle and place it in the data/imagecas/ directory.\")\n",
    "    print(\"Dataset URL: https://www.kaggle.com/datasets/xiaoweixumedicalai/imagecas\")\n",
    "else:\n",
    "    print(f\"✓ Data directory found: {data_dir}\")\n",
    "    \n",
    "    # List contents\n",
    "    image_files = sorted(list(data_dir.rglob('*image*.nii.gz')))\n",
    "    label_files = sorted(list(data_dir.rglob('*label*.nii.gz')))\n",
    "    \n",
    "    print(f\"\\nFound {len(image_files)} image files\")\n",
    "    print(f\"Found {len(label_files)} label files\")\n",
    "    \n",
    "    if len(image_files) > 0:\n",
    "        print(f\"\\nExample files:\")\n",
    "        print(f\"  Image: {image_files[0].name}\")\n",
    "        if len(label_files) > 0:\n",
    "            print(f\"  Label: {label_files[0].name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## 3. Data Preparation\n",
    "\n",
    "Create data dictionaries and split into train/validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data dictionaries\n",
    "if data_dir.exists() and len(image_files) > 0:\n",
    "    # Match images with labels\n",
    "    data_dicts = []\n",
    "    for img_path in image_files[:100]:  # Limit for quick testing\n",
    "        # Try to find corresponding label\n",
    "        # Adjust this logic based on actual ImageCAS naming convention\n",
    "        img_id = img_path.stem.replace('.nii', '').replace('image', '')\n",
    "        \n",
    "        # Search for matching label\n",
    "        label_path = None\n",
    "        for lbl_path in label_files:\n",
    "            if img_id in lbl_path.stem:\n",
    "                label_path = lbl_path\n",
    "                break\n",
    "        \n",
    "        if label_path:\n",
    "            data_dicts.append({\n",
    "                'image': str(img_path),\n",
    "                'label': str(label_path)\n",
    "            })\n",
    "    \n",
    "    print(f\"Created {len(data_dicts)} data pairs\")\n",
    "    \n",
    "    # Split into train/val (80/20)\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    train_files, val_files = train_test_split(\n",
    "        data_dicts, \n",
    "        test_size=0.2, \n",
    "        random_state=config['seed']\n",
    "    )\n",
    "    \n",
    "    # Apply data regime if specified\n",
    "    num_samples = config['data'].get('num_samples')\n",
    "    if num_samples and num_samples < len(train_files):\n",
    "        train_files = train_files[:num_samples]\n",
    "        print(f\"Using data regime with {num_samples} training samples\")\n",
    "    \n",
    "    print(f\"\\nTrain samples: {len(train_files)}\")\n",
    "    print(f\"Validation samples: {len(val_files)}\")\n",
    "else:\n",
    "    print(\"Cannot create data dictionaries - data not available\")\n",
    "    train_files = []\n",
    "    val_files = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## 4. Data Transforms\n",
    "\n",
    "Define preprocessing and augmentation transforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training transforms with augmentation\n",
    "train_transforms = Compose([\n",
    "    LoadImaged(keys=[\"image\", \"label\"]),\n",
    "    EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "    Spacingd(\n",
    "        keys=[\"image\", \"label\"],\n",
    "        pixdim=config['data']['pixdim'],\n",
    "        mode=(\"bilinear\", \"nearest\")\n",
    "    ),\n",
    "    ScaleIntensityRanged(\n",
    "        keys=[\"image\"],\n",
    "        a_min=config['data']['a_min'],\n",
    "        a_max=config['data']['a_max'],\n",
    "        b_min=0.0,\n",
    "        b_max=1.0,\n",
    "        clip=True\n",
    "    ),\n",
    "    RandCropByPosNegLabeld(\n",
    "        keys=[\"image\", \"label\"],\n",
    "        label_key=\"label\",\n",
    "        spatial_size=config['data']['spatial_size'],\n",
    "        pos=1,\n",
    "        neg=1,\n",
    "        num_samples=4\n",
    "    ),\n",
    "    RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=0),\n",
    "    RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=1),\n",
    "    RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=2),\n",
    "    RandRotate90d(keys=[\"image\", \"label\"], prob=0.5, max_k=3),\n",
    "])\n",
    "\n",
    "# Validation transforms (no augmentation)\n",
    "val_transforms = Compose([\n",
    "    LoadImaged(keys=[\"image\", \"label\"]),\n",
    "    EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "    Spacingd(\n",
    "        keys=[\"image\", \"label\"],\n",
    "        pixdim=config['data']['pixdim'],\n",
    "        mode=(\"bilinear\", \"nearest\")\n",
    "    ),\n",
    "    ScaleIntensityRanged(\n",
    "        keys=[\"image\"],\n",
    "        a_min=config['data']['a_min'],\n",
    "        a_max=config['data']['a_max'],\n",
    "        b_min=0.0,\n",
    "        b_max=1.0,\n",
    "        clip=True\n",
    "    ),\n",
    "])\n",
    "\n",
    "print(\"Transforms defined successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## 5. Create DataLoaders\n",
    "\n",
    "Create PyTorch DataLoaders for training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(train_files) > 0:\n",
    "    # Create datasets\n",
    "    train_ds = CacheDataset(\n",
    "        data=train_files,\n",
    "        transform=train_transforms,\n",
    "        cache_rate=0.5,\n",
    "        num_workers=config['data']['num_workers']\n",
    "    )\n",
    "    \n",
    "    val_ds = CacheDataset(\n",
    "        data=val_files,\n",
    "        transform=val_transforms,\n",
    "        cache_rate=1.0,\n",
    "        num_workers=config['data']['num_workers']\n",
    "    )\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=config['data']['batch_size'],\n",
    "        shuffle=True,\n",
    "        num_workers=config['data']['num_workers']\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_ds,\n",
    "        batch_size=1,\n",
    "        shuffle=False,\n",
    "        num_workers=config['data']['num_workers']\n",
    "    )\n",
    "    \n",
    "    print(f\"✓ DataLoaders created\")\n",
    "    print(f\"  Training batches: {len(train_loader)}\")\n",
    "    print(f\"  Validation batches: {len(val_loader)}\")\n",
    "else:\n",
    "    print(\"Cannot create DataLoaders - no training data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## 6. Visualize Sample Data\n",
    "\n",
    "Load and visualize a sample from the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(train_files) > 0:\n",
    "    # Get a batch\n",
    "    batch = next(iter(train_loader))\n",
    "    images = batch['image']\n",
    "    labels = batch['label']\n",
    "    \n",
    "    print(f\"Batch shape: {images.shape}\")\n",
    "    print(f\"Label shape: {labels.shape}\")\n",
    "    \n",
    "    # Visualize middle slice\n",
    "    sample_idx = 0\n",
    "    slice_idx = images.shape[-1] // 2\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    # Image\n",
    "    axes[0].imshow(images[sample_idx, 0, :, :, slice_idx].cpu(), cmap='gray')\n",
    "    axes[0].set_title('CT Image (Axial)')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Label\n",
    "    axes[1].imshow(labels[sample_idx, 0, :, :, slice_idx].cpu(), cmap='jet')\n",
    "    axes[1].set_title('Segmentation Label')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    # Overlay\n",
    "    axes[2].imshow(images[sample_idx, 0, :, :, slice_idx].cpu(), cmap='gray')\n",
    "    overlay = labels[sample_idx, 0, :, :, slice_idx].cpu()\n",
    "    axes[2].imshow(overlay, cmap='jet', alpha=0.3 * (overlay > 0))\n",
    "    axes[2].set_title('Overlay')\n",
    "    axes[2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "## 7. Model Setup\n",
    "\n",
    "Create the U-Net model with optional transfer learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create U-Net model\n",
    "model = UNet(\n",
    "    spatial_dims=3,\n",
    "    in_channels=config['model']['in_channels'],\n",
    "    out_channels=config['model']['out_channels'],\n",
    "    channels=config['model']['channels'],\n",
    "    strides=config['model']['strides'],\n",
    "    num_res_units=2,\n",
    ").to(device)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Model: {config['model']['architecture'].upper()}\")\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "\n",
    "# Loss function\n",
    "if config['training']['loss'] == 'dice':\n",
    "    loss_function = DiceLoss(to_onehot_y=True, softmax=True)\n",
    "elif config['training']['loss'] == 'dice_ce':\n",
    "    loss_function = DiceCELoss(to_onehot_y=True, softmax=True)\n",
    "else:\n",
    "    loss_function = DiceCELoss(to_onehot_y=True, softmax=True)\n",
    "\n",
    "print(f\"Loss function: {config['training']['loss']}\")\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=config['training']['learning_rate'],\n",
    "    weight_decay=config['training']['weight_decay']\n",
    ")\n",
    "\n",
    "print(f\"Optimizer: {config['training']['optimizer']}\")\n",
    "print(f\"Learning rate: {config['training']['learning_rate']}\")\n",
    "\n",
    "# Metric\n",
    "dice_metric = DiceMetric(include_background=False, reduction=\"mean\")\n",
    "\n",
    "print(\"\\n✓ Model setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## 8. Training Loop\n",
    "\n",
    "Train the model with validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train_epoch(model, loader, optimizer, loss_function, device):\n",
    "    \"\"\"Train for one epoch.\"\"\"\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for batch_data in tqdm(loader, desc=\"Training\"):\n",
    "        inputs = batch_data['image'].to(device)\n",
    "        labels = batch_data['label'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    return epoch_loss / len(loader)\n",
    "\n",
    "def validate(model, loader, metric, device):\n",
    "    \"\"\"Validate the model.\"\"\"\n",
    "    model.eval()\n",
    "    metric.reset()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_data in tqdm(loader, desc=\"Validation\"):\n",
    "            inputs = batch_data['image'].to(device)\n",
    "            labels = batch_data['label'].to(device)\n",
    "            \n",
    "            # Inference\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Compute metric\n",
    "            outputs = torch.argmax(outputs, dim=1, keepdim=True)\n",
    "            metric(y_pred=outputs, y=labels)\n",
    "    \n",
    "    # Aggregate metric\n",
    "    dice_score = metric.aggregate().item()\n",
    "    return dice_score\n",
    "\n",
    "print(\"Training functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "num_epochs = 10  # Reduced for notebook testing; use config['training']['epochs'] for full training\n",
    "best_dice = 0.0\n",
    "train_losses = []\n",
    "val_dices = []\n",
    "\n",
    "if len(train_files) > 0:\n",
    "    print(f\"Starting training for {num_epochs} epochs...\\n\")\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # Train\n",
    "        train_loss = train_epoch(model, train_loader, optimizer, loss_function, device)\n",
    "        train_losses.append(train_loss)\n",
    "        print(f\"Train Loss: {train_loss:.4f}\")\n",
    "        \n",
    "        # Validate\n",
    "        if (epoch + 1) % config['training']['val_interval'] == 0:\n",
    "            val_dice = validate(model, val_loader, dice_metric, device)\n",
    "            val_dices.append(val_dice)\n",
    "            print(f\"Validation Dice: {val_dice:.4f}\")\n",
    "            \n",
    "            # Save best model\n",
    "            if val_dice > best_dice:\n",
    "                best_dice = val_dice\n",
    "                checkpoint_dir = Path(config['logging']['checkpoint_dir'])\n",
    "                checkpoint_dir.mkdir(parents=True, exist_ok=True)\n",
    "                torch.save(\n",
    "                    model.state_dict(),\n",
    "                    checkpoint_dir / 'best_model.pth'\n",
    "                )\n",
    "                print(f\"✓ Saved new best model (Dice: {best_dice:.4f})\")\n",
    "        \n",
    "        print()\n",
    "    \n",
    "    print(f\"\\nTraining complete!\")\n",
    "    print(f\"Best validation Dice: {best_dice:.4f}\")\n",
    "else:\n",
    "    print(\"Cannot train - no training data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "## 9. Training Curves\n",
    "\n",
    "Visualize training loss and validation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(train_losses) > 0:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Training loss\n",
    "    axes[0].plot(range(1, len(train_losses) + 1), train_losses, 'b-', marker='o')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].set_title('Training Loss')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Validation Dice\n",
    "    if len(val_dices) > 0:\n",
    "        val_epochs = list(range(config['training']['val_interval'], \n",
    "                               len(train_losses) + 1, \n",
    "                               config['training']['val_interval']))\n",
    "        axes[1].plot(val_epochs, val_dices, 'g-', marker='s')\n",
    "        axes[1].set_xlabel('Epoch')\n",
    "        axes[1].set_ylabel('Dice Score')\n",
    "        axes[1].set_title('Validation Dice Score')\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "        axes[1].axhline(y=best_dice, color='r', linestyle='--', \n",
    "                       label=f'Best: {best_dice:.4f}')\n",
    "        axes[1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "## 10. Prediction Visualization\n",
    "\n",
    "Visualize predictions on validation samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(val_files) > 0:\n",
    "    model.eval()\n",
    "    \n",
    "    # Get a validation sample\n",
    "    val_batch = next(iter(val_loader))\n",
    "    val_image = val_batch['image'].to(device)\n",
    "    val_label = val_batch['label'].to(device)\n",
    "    \n",
    "    # Predict\n",
    "    with torch.no_grad():\n",
    "        val_output = model(val_image)\n",
    "        val_pred = torch.argmax(val_output, dim=1, keepdim=True)\n",
    "    \n",
    "    # Visualize\n",
    "    slice_idx = val_image.shape[-1] // 2\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
    "    \n",
    "    # Image\n",
    "    axes[0].imshow(val_image[0, 0, :, :, slice_idx].cpu(), cmap='gray')\n",
    "    axes[0].set_title('Input Image')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Ground truth\n",
    "    axes[1].imshow(val_label[0, 0, :, :, slice_idx].cpu(), cmap='jet')\n",
    "    axes[1].set_title('Ground Truth')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    # Prediction\n",
    "    axes[2].imshow(val_pred[0, 0, :, :, slice_idx].cpu(), cmap='jet')\n",
    "    axes[2].set_title('Prediction')\n",
    "    axes[2].axis('off')\n",
    "    \n",
    "    # Overlay\n",
    "    axes[3].imshow(val_image[0, 0, :, :, slice_idx].cpu(), cmap='gray')\n",
    "    pred_overlay = val_pred[0, 0, :, :, slice_idx].cpu()\n",
    "    axes[3].imshow(pred_overlay, cmap='jet', alpha=0.3 * (pred_overlay > 0))\n",
    "    axes[3].set_title('Overlay')\n",
    "    axes[3].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Compute Dice for this sample\n",
    "    dice_metric.reset()\n",
    "    dice_metric(y_pred=val_pred, y=val_label)\n",
    "    sample_dice = dice_metric.aggregate().item()\n",
    "    print(f\"Dice score for this sample: {sample_dice:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "## 11. Export Results\n",
    "\n",
    "Save training history and metrics to CSV for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(train_losses) > 0:\n",
    "    # Create results dataframe\n",
    "    results = pd.DataFrame({\n",
    "        'epoch': range(1, len(train_losses) + 1),\n",
    "        'train_loss': train_losses\n",
    "    })\n",
    "    \n",
    "    # Add validation scores (where available)\n",
    "    results['val_dice'] = None\n",
    "    val_epochs = list(range(config['training']['val_interval'], \n",
    "                           len(train_losses) + 1, \n",
    "                           config['training']['val_interval']))\n",
    "    for i, epoch in enumerate(val_epochs):\n",
    "        if i < len(val_dices):\n",
    "            results.loc[epoch - 1, 'val_dice'] = val_dices[i]\n",
    "    \n",
    "    # Save to CSV\n",
    "    results_dir = Path('../experiments/results')\n",
    "    results_dir.mkdir(parents=True, exist_ok=True)\n",
    "    results.to_csv(results_dir / 'training_history.csv', index=False)\n",
    "    \n",
    "    print(\"✓ Results saved to experiments/results/training_history.csv\")\n",
    "    print(\"\\nTraining Summary:\")\n",
    "    display(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-25",
   "metadata": {},
   "source": [
    "## 12. Next Steps\n",
    "\n",
    "**Experiment with different configurations:**\n",
    "1. Test different data regimes (5, 10, 20, 30, 50, 100, 200 cases)\n",
    "2. Try transfer learning with pretrained encoders (ImageNet, RadImageNet, CT-FM)\n",
    "3. Evaluate on ASOCA dataset for benchmark comparison\n",
    "4. Implement 5-fold cross-validation\n",
    "5. Generate publication-ready figures and tables\n",
    "\n",
    "**Model improvements:**\n",
    "- Experiment with deeper architectures\n",
    "- Try attention mechanisms\n",
    "- Test different loss functions (Focal, Tversky)\n",
    "- Implement post-processing (connected components, morphological operations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
